{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Browser_Used</th>\n",
       "      <th>Device_Used</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>id17093</td>\n",
       "      <td>We stayed here for the last two nights of our ...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>id19652</td>\n",
       "      <td>We booked this hotel through Priceline (for a ...</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>id34479</td>\n",
       "      <td>Love the style of this place, and I don't mean...</td>\n",
       "      <td>Safari</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>id25711</td>\n",
       "      <td>I stayed at The Langham, Boston on Friday July...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>id29439</td>\n",
       "      <td>and Warm Cookies too. really nice breakfast bu...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID                                        Description  \\\n",
       "0  id17093  We stayed here for the last two nights of our ...   \n",
       "1  id19652  We booked this hotel through Priceline (for a ...   \n",
       "2  id34479  Love the style of this place, and I don't mean...   \n",
       "3  id25711  I stayed at The Langham, Boston on Friday July...   \n",
       "4  id29439  and Warm Cookies too. really nice breakfast bu...   \n",
       "\n",
       "       Browser_Used Device_Used Is_Response  \n",
       "0              Edge     Desktop       happy  \n",
       "1           Firefox     Desktop       happy  \n",
       "2            Safari      Tablet       happy  \n",
       "3  InternetExplorer      Mobile       happy  \n",
       "4              Edge      Tablet   not happy  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "df=df.sample(frac=1).reset_index(drop=True) # Shuffling the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.iloc[:5000,:] # selecting only 5000 rows as large file will not run in the system\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy        3439\n",
       "not happy    1561\n",
       "Name: Is_Response, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Is_Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>We stayed here for the last two nights of our ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>We booked this hotel through Priceline (for a ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Love the style of this place, and I don't mean...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I stayed at The Langham, Boston on Friday July...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>and Warm Cookies too. really nice breakfast bu...</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description Is_Response\n",
       "0  We stayed here for the last two nights of our ...       happy\n",
       "1  We booked this hotel through Priceline (for a ...       happy\n",
       "2  Love the style of this place, and I don't mean...       happy\n",
       "3  I stayed at The Langham, Boston on Friday July...       happy\n",
       "4  and Warm Cookies too. really nice breakfast bu...   not happy"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping columns like user_id, browser used and device used which is of no much importance\n",
    "df.drop(['User_ID', 'Browser_Used', 'Device_Used'],axis=1,inplace=True) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import Counter\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Description']=df['Description'].str.lower()\n",
    "#remove punctuation\n",
    "df['Description']=df['Description'].str.replace(r'[^\\w\\d\\s]',' ')\n",
    "# Replace whitespace between terms with a single space\n",
    "df['Description']=df['Description'].str.replace(r'\\s+', ' ')\n",
    "# Remove leading and trailing whitespace\n",
    "df['Description'] = df['Description'].str.replace(r'^\\s+|\\s+?$', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       stayed last two nights west coast tour june su...\n",
      "1       booked hotel priceline great rate since needed...\n",
      "2       love style place mean visually although cute m...\n",
      "3       stayed langham boston friday july st parents s...\n",
      "4       warm cookies really nice breakfast buffet get ...\n",
      "                              ...                        \n",
      "4995    boyfriend recently stayed donatello say enough...\n",
      "4996    love san francisco wife stayed part honeymoon ...\n",
      "4997    husband stayed pearl honeymoon read reviews we...\n",
      "4998    decided hotel difficult find hotel new york wi...\n",
      "4999    husband returned fantastic stay sofitel celebr...\n",
      "Name: Description, Length: 5000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['Description']=df['Description'].apply(lambda x: ' '.join(term for term in x.split() if term not in stopwords.words('english')))\n",
    "\n",
    "print(df['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1517.5570000000064\n",
      "275.87700000000024\n",
      "3206.551\n"
     ]
    }
   ],
   "source": [
    "positive=[]\n",
    "negative=[]\n",
    "neutral=[]\n",
    "for i in df['Description']:\n",
    "    sia=SentimentIntensityAnalyzer()\n",
    "    positive.append(sia.polarity_scores(i)['pos'])\n",
    "    negative.append(sia.polarity_scores(i)['neg'])\n",
    "    neutral.append(sia.polarity_scores(i)['neu'])\n",
    "print(sum(positive))\n",
    "print(sum(negative))\n",
    "print(sum(neutral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_polarity=pd.DataFrame({'Positive':[sum(positive)], 'Negative':[sum(negative)], 'Neutral':[sum(neutral)]})\n",
    "plt.figure()\n",
    "v=[sum(positive), sum(negative), sum(neutral)]\n",
    "pol=['Positive','Negative','Neutral']\n",
    "plt.bar(pol,v)\n",
    "plt.title('Polarity Sentiment Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation\n",
    "1. From Polarity Sentiment Comparison, we understood that Neutral score is the highest, which could be normal words used in the reviews and positive scores are more than negative scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "stemmer=SnowballStemmer(\"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing function for entire dataset\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text,pos='v'))\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token)>2:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[] \n",
    "for doc in df['Description']:\n",
    "    for token in gensim.utils.simple_preprocess(doc):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token)>2:\n",
    "            result.append(stemmer.stem(WordNetLemmatizer().lemmatize(token)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs=[]\n",
    "for doc in df['Description']:\n",
    "    processed_docs.append(preprocess(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary on a dataset\n",
    "dictionary=gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(11938 unique tokens: ['ador', 'breakfast', 'bun', 'choic', 'cinnamon']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ador\n",
      "1 breakfast\n",
      "2 bun\n",
      "3 choic\n",
      "4 cinnamon\n",
      "5 citi\n",
      "6 clean\n",
      "7 coast\n",
      "8 come\n",
      "9 expect\n",
      "10 fisherman\n",
      "11 francisco\n",
      "12 friend\n",
      "13 good\n",
      "14 great\n",
      "15 heart\n",
      "16 help\n",
      "17 high\n",
      "18 hotel\n",
      "19 ideal\n",
      "20 june\n"
     ]
    }
   ],
   "source": [
    "# Let us see if dictionary is created successfully\n",
    "count=0\n",
    "for k,v in dictionary.iteritems():\n",
    "    print (k,v)\n",
    "    count +=1\n",
    "    if count>20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rare and repetitive words\n",
    "dictionary.filter_extremes(no_below=15,no_above=0.1,keep_n=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1868 unique tokens: ['choic', 'coast', 'fisherman', 'francisco', 'heart']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many\n",
    "#words and how many times those words appear. Save this to 'bow_corpus'\n",
    "bow_corpus=[dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1),\n",
       " (10, 1),\n",
       " (11, 1),\n",
       " (12, 1),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 1)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary and bow corpus are separate and are not related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 8 (\"modern\") appears 1 time.\n",
      "Word 41 (\"updat\") appears 1 time.\n",
      "Word 53 (\"easi\") appears 1 time.\n",
      "Word 106 (\"husband\") appears 1 time.\n",
      "Word 154 (\"build\") appears 1 time.\n",
      "Word 285 (\"hear\") appears 1 time.\n",
      "Word 335 (\"capit\") appears 1 time.\n",
      "Word 336 (\"cost\") appears 1 time.\n",
      "Word 337 (\"cramp\") appears 1 time.\n",
      "Word 338 (\"even\") appears 1 time.\n",
      "Word 339 (\"extra\") appears 1 time.\n",
      "Word 340 (\"featur\") appears 1 time.\n",
      "Word 341 (\"furnitur\") appears 1 time.\n",
      "Word 342 (\"half\") appears 1 time.\n",
      "Word 343 (\"happen\") appears 1 time.\n",
      "Word 344 (\"marathon\") appears 1 time.\n",
      "Word 345 (\"super\") appears 1 time.\n",
      "Word 346 (\"upper\") appears 1 time.\n",
      "Word 347 (\"worri\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "# preview\n",
    "document_num=10\n",
    "bow_doc_x=bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], dictionary[bow_doc_x[i][0]], bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model=gensim.models.LdaMulticore(bow_corpus,num_topics=30,id2word=dictionary,passes=10,workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 11 \n",
      "Words: 0.014*\"manag\" + 0.012*\"dirti\" + 0.011*\"quiet\" + 0.010*\"hyatt\" + 0.009*\"call\" + 0.009*\"blanket\" + 0.008*\"wonder\" + 0.007*\"charg\" + 0.007*\"york\" + 0.007*\"say\"\n",
      "\n",
      "\n",
      "Topic: 22 \n",
      "Words: 0.012*\"resort\" + 0.009*\"say\" + 0.008*\"big\" + 0.008*\"standard\" + 0.007*\"doubl\" + 0.007*\"bath\" + 0.007*\"spend\" + 0.007*\"sure\" + 0.007*\"westin\" + 0.007*\"surpris\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.016*\"car\" + 0.012*\"motel\" + 0.012*\"say\" + 0.009*\"light\" + 0.009*\"overal\" + 0.009*\"advis\" + 0.009*\"disappoint\" + 0.009*\"rate\" + 0.008*\"inn\" + 0.008*\"reserv\"\n",
      "\n",
      "\n",
      "Topic: 13 \n",
      "Words: 0.012*\"downtown\" + 0.011*\"town\" + 0.011*\"car\" + 0.010*\"conveni\" + 0.010*\"san\" + 0.008*\"drive\" + 0.008*\"basic\" + 0.008*\"anniversari\" + 0.008*\"easi\" + 0.007*\"valu\"\n",
      "\n",
      "\n",
      "Topic: 21 \n",
      "Words: 0.013*\"dinner\" + 0.011*\"properti\" + 0.008*\"even\" + 0.008*\"eat\" + 0.007*\"decor\" + 0.007*\"voucher\" + 0.007*\"recept\" + 0.006*\"sure\" + 0.006*\"tri\" + 0.006*\"call\"\n",
      "\n",
      "\n",
      "Topic: 25 \n",
      "Words: 0.009*\"inn\" + 0.009*\"cool\" + 0.009*\"reason\" + 0.008*\"girl\" + 0.008*\"weekend\" + 0.007*\"entir\" + 0.007*\"downtown\" + 0.006*\"week\" + 0.005*\"thank\" + 0.005*\"central\"\n",
      "\n",
      "\n",
      "Topic: 27 \n",
      "Words: 0.011*\"know\" + 0.011*\"manag\" + 0.011*\"charg\" + 0.008*\"wait\" + 0.008*\"key\" + 0.007*\"receiv\" + 0.007*\"final\" + 0.007*\"say\" + 0.007*\"elev\" + 0.007*\"call\"\n",
      "\n",
      "\n",
      "Topic: 14 \n",
      "Words: 0.014*\"build\" + 0.013*\"husband\" + 0.011*\"decor\" + 0.010*\"state\" + 0.009*\"empir\" + 0.008*\"window\" + 0.008*\"nyc\" + 0.008*\"famili\" + 0.008*\"year\" + 0.007*\"easi\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.018*\"dog\" + 0.012*\"beach\" + 0.011*\"pet\" + 0.010*\"beauti\" + 0.008*\"tea\" + 0.008*\"ocean\" + 0.008*\"seattl\" + 0.007*\"center\" + 0.007*\"milk\" + 0.006*\"water\"\n",
      "\n",
      "\n",
      "Topic: 17 \n",
      "Words: 0.013*\"center\" + 0.011*\"space\" + 0.011*\"convent\" + 0.010*\"conveni\" + 0.010*\"downtown\" + 0.009*\"open\" + 0.007*\"call\" + 0.007*\"charg\" + 0.007*\"late\" + 0.006*\"water\"\n",
      "\n",
      "\n",
      "Topic: 29 \n",
      "Words: 0.017*\"easi\" + 0.015*\"downtown\" + 0.015*\"access\" + 0.012*\"internet\" + 0.011*\"wifi\" + 0.011*\"distanc\" + 0.010*\"chicago\" + 0.010*\"includ\" + 0.010*\"subway\" + 0.009*\"line\"\n",
      "\n",
      "\n",
      "Topic: 15 \n",
      "Words: 0.013*\"water\" + 0.011*\"toilet\" + 0.009*\"turn\" + 0.008*\"near\" + 0.008*\"run\" + 0.007*\"know\" + 0.007*\"star\" + 0.007*\"quiet\" + 0.007*\"averag\" + 0.007*\"year\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.012*\"hear\" + 0.011*\"feel\" + 0.011*\"light\" + 0.011*\"valu\" + 0.009*\"wall\" + 0.009*\"hallway\" + 0.008*\"quiet\" + 0.008*\"car\" + 0.008*\"confer\" + 0.007*\"phone\"\n",
      "\n",
      "\n",
      "Topic: 26 \n",
      "Words: 0.013*\"charg\" + 0.011*\"pleasant\" + 0.010*\"famili\" + 0.009*\"internet\" + 0.009*\"money\" + 0.009*\"water\" + 0.007*\"surpris\" + 0.007*\"dupont\" + 0.007*\"reserv\" + 0.007*\"issu\"\n",
      "\n",
      "\n",
      "Topic: 16 \n",
      "Words: 0.011*\"home\" + 0.008*\"greet\" + 0.007*\"sign\" + 0.007*\"long\" + 0.007*\"hot\" + 0.006*\"know\" + 0.006*\"manag\" + 0.006*\"let\" + 0.006*\"towel\" + 0.006*\"call\"\n",
      "\n",
      "\n",
      "Topic: 20 \n",
      "Words: 0.031*\"airport\" + 0.025*\"shuttl\" + 0.012*\"charg\" + 0.011*\"easi\" + 0.011*\"conveni\" + 0.010*\"flight\" + 0.009*\"access\" + 0.009*\"car\" + 0.009*\"station\" + 0.009*\"internet\"\n",
      "\n",
      "\n",
      "Topic: 24 \n",
      "Words: 0.011*\"window\" + 0.009*\"wait\" + 0.009*\"sit\" + 0.008*\"air\" + 0.007*\"microwav\" + 0.007*\"king\" + 0.007*\"club\" + 0.006*\"big\" + 0.006*\"includ\" + 0.006*\"eat\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.022*\"bug\" + 0.013*\"wed\" + 0.009*\"week\" + 0.008*\"happi\" + 0.008*\"town\" + 0.008*\"earli\" + 0.007*\"manag\" + 0.007*\"pillow\" + 0.006*\"uncomfort\" + 0.006*\"decor\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.009*\"hot\" + 0.009*\"bath\" + 0.008*\"king\" + 0.008*\"window\" + 0.008*\"wait\" + 0.006*\"water\" + 0.006*\"light\" + 0.006*\"call\" + 0.006*\"linen\" + 0.005*\"doubl\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.017*\"hilton\" + 0.009*\"tower\" + 0.008*\"kid\" + 0.008*\"fruit\" + 0.007*\"juic\" + 0.007*\"egg\" + 0.007*\"cereal\" + 0.007*\"towel\" + 0.006*\"diego\" + 0.006*\"inn\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics():\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx,topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations from the topic modelling:-\n",
    "\n",
    "Topic: 11 \n",
    "Words: 0.014*\"manag\" + 0.012*\"dirti\" + 0.011*\"quiet\" + 0.010*\"hyatt\" + 0.009*\"call\" + 0.009*\"blanket\" + 0.008*\"wonder\" + 0.007*\"charg\" + 0.007*\"york\" + 0.007*\"say\"\n",
    "\n",
    "This indicates a negative reviews with words like dirt blanket etc\n",
    "\n",
    "Topic: 7 \n",
    "Words: 0.016*\"car\" + 0.012*\"motel\" + 0.012*\"say\" + 0.009*\"light\" + 0.009*\"overal\" + 0.009*\"advis\" + 0.009*\"disappoint\" + 0.009*\"rate\" + 0.008*\"inn\" + 0.008*\"reserv\"\n",
    "\n",
    "---> This indicates a negative review with words like disappint, advise, overall etc\n",
    "\n",
    "Topic: 13 \n",
    "Words: 0.012*\"downtown\" + 0.011*\"town\" + 0.011*\"car\" + 0.010*\"conveni\" + 0.010*\"san\" + 0.008*\"drive\" + 0.008*\"basic\" + 0.008*\"anniversari\" + 0.008*\"easi\" + 0.007*\"valu\"\n",
    "\n",
    "---> This refers to a positive review which is indicated by words like easi, value, convenient etc\n",
    "    \n",
    "Topic: 20 \n",
    "Words: 0.031*\"airport\" + 0.025*\"shuttl\" + 0.012*\"charg\" + 0.011*\"easi\" + 0.011*\"conveni\" + 0.010*\"flight\" + 0.009*\"access\" + 0.009*\"car\" + 0.009*\"station\" + 0.009*\"internet\"\n",
    "\n",
    "---> This indicates a positive review with words like easy, convenient etc\n",
    "    \n",
    "Topic: 6 \n",
    "Words: 0.022*\"bug\" + 0.013*\"wed\" + 0.009*\"week\" + 0.008*\"happi\" + 0.008*\"town\" + 0.008*\"earli\" + 0.007*\"manag\" + 0.007*\"pillow\" + 0.006*\"uncomfort\" + 0.006*\"decor\"\n",
    "\n",
    "---> This indicates a negative review with words like bug, uncomfort etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
